#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°ç‰ˆæœ¬Centimaniæ–‡ä»¶åˆ†æå·¥å…·

ç”¨æ–¼åˆ†æ2023å¹´å¹³å°åŸ¹è¨“çš„æ–°ç‰ˆæœ¬æ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š
1. æ–°ç‰ˆæœ¬PPT (20210217)
2. æ–°ç‰ˆæœ¬å„€å™¨åƒæ•¸ (Ver1.71)
3. æ–°ç‰ˆæœ¬è…³æœ¬ç”¨æˆ¶æŒ‡å—
4. iPLASåƒæ•¸åˆ—è¡¨

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
æ›´æ–°æ—¥æœŸ: 2025-08-11
"""

import os
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

try:
    from pptx import Presentation
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

class NewVersionAnalyzer:
    """æ–°ç‰ˆæœ¬Centimaniæ–‡ä»¶åˆ†æå™¨"""
    
    def __init__(self):
        self.analysis_result = {
            "analysis_time": datetime.now().isoformat(),
            "new_versions": {},
            "version_comparison": {},
            "new_features": [],
            "updated_rules": [],
            "recommendations": []
        }
    
    def analyze_new_versions(self, base_path: str):
        """åˆ†ææ–°ç‰ˆæœ¬æ–‡ä»¶"""
        print("ğŸ” é–‹å§‹åˆ†ææ–°ç‰ˆæœ¬Centimaniæ–‡ä»¶...")
        
        # åˆ†ææ–°ç‰ˆæœ¬PPT
        ppt_path = os.path.join(base_path, "Centimani - How to edit scripts (20210217).pptx")
        if os.path.exists(ppt_path):
            self._analyze_new_ppt(ppt_path)
        
        # åˆ†ææ–°ç‰ˆæœ¬å„€å™¨åƒæ•¸
        instrument_path = os.path.join(base_path, "Centimani instrument parameter -Ver1.71(20230411).xlsx")
        if os.path.exists(instrument_path):
            self._analyze_new_instrument_params(instrument_path)
        
        # åˆ†ææ–°ç‰ˆæœ¬è…³æœ¬ç”¨æˆ¶æŒ‡å—
        script_guide_path = os.path.join(base_path, "Centimani Script User Guide(202230104).xlsx")
        if os.path.exists(script_guide_path):
            self._analyze_new_script_guide(script_guide_path)
        
        # åˆ†æiPLASåƒæ•¸åˆ—è¡¨
        iplas_path = os.path.join(base_path, "dbaccess2_iPLAS_Argument_List_v2.0.xlsx")
        if os.path.exists(iplas_path):
            self._analyze_iplas_params(iplas_path)
        
        # ç”Ÿæˆç‰ˆæœ¬æ¯”è¼ƒ
        self._generate_version_comparison()
        
        # ç”Ÿæˆæ›´æ–°å»ºè­°
        self._generate_update_recommendations()
        
        print("âœ… æ–°ç‰ˆæœ¬åˆ†æå®Œæˆï¼")
        return self.analysis_result
    
    def _analyze_new_ppt(self, ppt_path: str):
        """åˆ†ææ–°ç‰ˆæœ¬PPT"""
        if not PPTX_AVAILABLE:
            print("âš ï¸ ç„¡æ³•åˆ†æPPTæ–‡ä»¶ï¼Œpython-pptxæœªå®‰è£")
            return
        
        try:
            print(f"ğŸ“Š åˆ†ææ–°ç‰ˆæœ¬PPT: {os.path.basename(ppt_path)}")
            prs = Presentation(ppt_path)
            
            self.analysis_result["new_versions"]["ppt"] = {
                "file_name": os.path.basename(ppt_path),
                "file_size": os.path.getsize(ppt_path),
                "total_slides": len(prs.slides),
                "slide_width": prs.slide_width,
                "slide_height": prs.slide_height,
                "slides_content": []
            }
            
            # åˆ†ææ¯å€‹å¹»ç‡ˆç‰‡
            for slide_num, slide in enumerate(prs.slides, 1):
                slide_text = self._extract_slide_text(slide)
                if slide_text:
                    self.analysis_result["new_versions"]["ppt"]["slides_content"].append({
                        "slide": slide_num,
                        "text": slide_text
                    })
            
            print(f"   - ç¸½å¹»ç‡ˆç‰‡æ•¸: {len(prs.slides)}")
            print(f"   - æ–‡å­—å…§å®¹æ•¸: {len(self.analysis_result['new_versions']['ppt']['slides_content'])}")
            
        except Exception as e:
            print(f"âŒ PPTåˆ†æå¤±æ•—: {e}")
    
    def _analyze_new_instrument_params(self, excel_path: str):
        """åˆ†ææ–°ç‰ˆæœ¬å„€å™¨åƒæ•¸"""
        if not PANDAS_AVAILABLE:
            print("âš ï¸ ç„¡æ³•åˆ†æExcelæ–‡ä»¶ï¼Œpandasæœªå®‰è£")
            return
        
        try:
            print(f"ğŸ“Š åˆ†ææ–°ç‰ˆæœ¬å„€å™¨åƒæ•¸: {os.path.basename(excel_path)}")
            
            # å˜—è©¦è®€å–Excelæ–‡ä»¶
            excel_file = pd.ExcelFile(excel_path)
            sheet_names = excel_file.sheet_names
            
            self.analysis_result["new_versions"]["instrument_params"] = {
                "file_name": os.path.basename(excel_path),
                "file_size": os.path.getsize(excel_path),
                "sheet_names": sheet_names,
                "sheets_info": {}
            }
            
            # åˆ†ææ¯å€‹å·¥ä½œè¡¨
            for sheet_name in sheet_names:
                try:
                    df = pd.read_excel(excel_path, sheet_name=sheet_name)
                    self.analysis_result["new_versions"]["instrument_params"]["sheets_info"][sheet_name] = {
                        "rows": len(df),
                        "columns": len(df.columns),
                        "column_names": df.columns.tolist(),
                        "sample_data": df.head(3).to_dict('records') if len(df) > 0 else []
                    }
                except Exception as e:
                    print(f"   - å·¥ä½œè¡¨ {sheet_name} åˆ†æå¤±æ•—: {e}")
            
            print(f"   - å·¥ä½œè¡¨æ•¸: {len(sheet_names)}")
            print(f"   - å·¥ä½œè¡¨: {', '.join(sheet_names)}")
            
        except Exception as e:
            print(f"âŒ å„€å™¨åƒæ•¸åˆ†æå¤±æ•—: {e}")
    
    def _analyze_new_script_guide(self, excel_path: str):
        """åˆ†ææ–°ç‰ˆæœ¬è…³æœ¬ç”¨æˆ¶æŒ‡å—"""
        if not PANDAS_AVAILABLE:
            print("âš ï¸ ç„¡æ³•åˆ†æExcelæ–‡ä»¶ï¼Œpandasæœªå®‰è£")
            return
        
        try:
            print(f"ğŸ“Š åˆ†ææ–°ç‰ˆæœ¬è…³æœ¬ç”¨æˆ¶æŒ‡å—: {os.path.basename(excel_path)}")
            
            excel_file = pd.ExcelFile(excel_path)
            sheet_names = excel_file.sheet_names
            
            self.analysis_result["new_versions"]["script_guide"] = {
                "file_name": os.path.basename(excel_path),
                "file_size": os.path.getsize(excel_path),
                "sheet_names": sheet_names,
                "sheets_info": {}
            }
            
            # åˆ†ææ¯å€‹å·¥ä½œè¡¨
            for sheet_name in sheet_names:
                try:
                    df = pd.read_excel(excel_path, sheet_name=sheet_name)
                    self.analysis_result["new_versions"]["script_guide"]["sheets_info"][sheet_name] = {
                        "rows": len(df),
                        "columns": len(df.columns),
                        "column_names": df.columns.tolist(),
                        "sample_data": df.head(3).to_dict('records') if len(df) > 0 else []
                    }
                except Exception as e:
                    print(f"   - å·¥ä½œè¡¨ {sheet_name} åˆ†æå¤±æ•—: {e}")
            
            print(f"   - å·¥ä½œè¡¨æ•¸: {len(sheet_names)}")
            print(f"   - å·¥ä½œè¡¨: {', '.join(sheet_names)}")
            
        except Exception as e:
            print(f"âŒ è…³æœ¬ç”¨æˆ¶æŒ‡å—åˆ†æå¤±æ•—: {e}")
    
    def _analyze_iplas_params(self, excel_path: str):
        """åˆ†æiPLASåƒæ•¸åˆ—è¡¨"""
        if not PANDAS_AVAILABLE:
            print("âš ï¸ ç„¡æ³•åˆ†æExcelæ–‡ä»¶ï¼Œpandasæœªå®‰è£")
            return
        
        try:
            print(f"ğŸ“Š åˆ†æiPLASåƒæ•¸åˆ—è¡¨: {os.path.basename(excel_path)}")
            
            excel_file = pd.ExcelFile(excel_path)
            sheet_names = excel_file.sheet_names
            
            self.analysis_result["new_versions"]["iplas_params"] = {
                "file_name": os.path.basename(excel_path),
                "file_size": os.path.getsize(excel_path),
                "sheet_names": sheet_names,
                "sheets_info": {}
            }
            
            # åˆ†ææ¯å€‹å·¥ä½œè¡¨
            for sheet_name in sheet_names:
                try:
                    df = pd.read_excel(excel_path, sheet_name=sheet_name)
                    self.analysis_result["new_versions"]["iplas_params"]["sheets_info"][sheet_name] = {
                        "rows": len(df),
                        "columns": len(df.columns),
                        "column_names": df.columns.tolist(),
                        "sample_data": df.head(3).to_dict('records') if len(df) > 0 else []
                    }
                except Exception as e:
                    print(f"   - å·¥ä½œè¡¨ {sheet_name} åˆ†æå¤±æ•—: {e}")
            
            print(f"   - å·¥ä½œè¡¨æ•¸: {len(sheet_names)}")
            print(f"   - å·¥ä½œè¡¨: {', '.join(sheet_names)}")
            
        except Exception as e:
            print(f"âŒ iPLASåƒæ•¸åˆ†æå¤±æ•—: {e}")
    
    def _extract_slide_text(self, slide) -> str:
        """æå–å¹»ç‡ˆç‰‡æ–‡å­—å…§å®¹"""
        text_content = []
        
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text.strip():
                text_content.append(shape.text.strip())
        
        return " | ".join(text_content) if text_content else ""
    
    def _generate_version_comparison(self):
        """ç”Ÿæˆç‰ˆæœ¬æ¯”è¼ƒ"""
        print("ğŸ”„ ç”Ÿæˆç‰ˆæœ¬æ¯”è¼ƒ...")
        
        # æ¯”è¼ƒPPTç‰ˆæœ¬
        if "ppt" in self.analysis_result["new_versions"]:
            old_ppt_info = {
                "version": "v1.4(20180427)",
                "total_slides": 19
            }
            
            new_ppt_info = self.analysis_result["new_versions"]["ppt"]
            
            self.analysis_result["version_comparison"]["ppt"] = {
                "old_version": old_ppt_info,
                "new_version": {
                    "version": "(20210217)",
                    "total_slides": new_ppt_info.get("total_slides", 0)
                },
                "changes": {
                    "slide_count_change": new_ppt_info.get("total_slides", 0) - old_ppt_info["total_slides"],
                    "update_date": "2021-02-17 (vs 2018-04-27)"
                }
            }
        
        # æ¯”è¼ƒå„€å™¨åƒæ•¸ç‰ˆæœ¬
        if "instrument_params" in self.analysis_result["new_versions"]:
            old_instrument_info = {
                "version": "Ver1.65 (20230104)",
                "update_date": "2023-01-04"
            }
            
            new_instrument_info = {
                "version": "Ver1.71(20230411)",
                "update_date": "2023-04-11"
            }
            
            self.analysis_result["version_comparison"]["instrument_params"] = {
                "old_version": old_instrument_info,
                "new_version": new_instrument_info,
                "changes": {
                    "version_increment": "1.65 â†’ 1.71",
                    "update_date": "2023-04-11 (vs 2023-01-04)",
                    "time_gap": "3å€‹æœˆ"
                }
            }
    
    def _generate_update_recommendations(self):
        """ç”Ÿæˆæ›´æ–°å»ºè­°"""
        print("ğŸ’¡ ç”Ÿæˆæ›´æ–°å»ºè­°...")
        
        recommendations = []
        
        # åŸºæ–¼ç‰ˆæœ¬æ¯”è¼ƒçš„å»ºè­°
        if "ppt" in self.analysis_result["version_comparison"]:
            ppt_comp = self.analysis_result["version_comparison"]["ppt"]
            if ppt_comp["changes"]["slide_count_change"] != 0:
                recommendations.append({
                    "type": "ppt_update",
                    "priority": "high",
                    "description": f"PPTç‰ˆæœ¬å·²æ›´æ–°è‡³{ppt_comp['new_version']['version']}ï¼Œå»ºè­°æ›´æ–°é€ŸæŸ¥è¡¨å…§å®¹",
                    "action": "åˆ†ææ–°ç‰ˆæœ¬PPTçš„å·®ç•°ï¼Œæ›´æ–°é€ŸæŸ¥è¡¨"
                })
        
        if "instrument_params" in self.analysis_result["version_comparison"]:
            inst_comp = self.analysis_result["version_comparison"]["instrument_params"]
            recommendations.append({
                "type": "instrument_update",
                "priority": "medium",
                "description": f"å„€å™¨åƒæ•¸å·²æ›´æ–°è‡³{inst_comp['new_version']['version']}ï¼ŒåŒ…å«æ–°åŠŸèƒ½å’Œåƒæ•¸",
                "action": "æª¢æŸ¥æ–°ç‰ˆæœ¬å„€å™¨åƒæ•¸ï¼Œæ›´æ–°ç›¸é—œè¨­å®šèªªæ˜"
            })
        
        # åŸºæ–¼æ–°åŠŸèƒ½çš„å»ºè­°
        if "iplas_params" in self.analysis_result["new_versions"]:
            recommendations.append({
                "type": "new_feature",
                "priority": "high",
                "description": "æ–°å¢iPLASåƒæ•¸åˆ—è¡¨v2.0ï¼ŒåŒ…å«æ–°çš„åƒæ•¸å’ŒåŠŸèƒ½",
                "action": "å°‡iPLASåƒæ•¸æ•´åˆåˆ°é€ŸæŸ¥è¡¨ä¸­ï¼Œæä¾›å®Œæ•´çš„åƒæ•¸åƒè€ƒ"
            })
        
        # é€šç”¨å»ºè­°
        recommendations.extend([
            {
                "type": "general",
                "priority": "medium",
                "description": "æ–°ç‰ˆæœ¬æ–‡ä»¶åŒ…å«æ›´å¤šå¯¦ç”¨è³‡è¨Šå’Œæœ€ä½³å¯¦è¸",
                "action": "å®šæœŸæª¢æŸ¥å’Œæ›´æ–°é€ŸæŸ¥è¡¨ï¼Œä¿æŒèˆ‡æœ€æ–°ç‰ˆæœ¬åŒæ­¥"
            },
            {
                "type": "integration",
                "priority": "low",
                "description": "è€ƒæ…®å°‡æ–°ç‰ˆæœ¬å…§å®¹èˆ‡ç¾æœ‰é€ŸæŸ¥è¡¨æ•´åˆ",
                "action": "å‰µå»ºç‰ˆæœ¬å°ç…§è¡¨ï¼Œå¹«åŠ©ç”¨æˆ¶äº†è§£ç‰ˆæœ¬å·®ç•°"
            }
        ])
        
        self.analysis_result["recommendations"] = recommendations
    
    def save_analysis_report(self, output_file: str = None) -> str:
        """ä¿å­˜åˆ†æå ±å‘Š"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"New_Version_Analysis_Report_{timestamp}.json"
        
        try:
            # å‰µå»ºå¯åºåˆ—åŒ–çš„å‰¯æœ¬
            serializable_result = self._make_serializable(self.analysis_result)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_result, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ åˆ†æå ±å‘Šå·²ä¿å­˜: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"âŒ ä¿å­˜åˆ†æå ±å‘Šå¤±æ•—: {e}")
            return ""
    
    def _make_serializable(self, obj):
        """å°‡å°è±¡è½‰æ›ç‚ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif isinstance(obj, datetime):
            return obj.isoformat()
        else:
            return obj
    
    def generate_update_summary(self) -> str:
        """ç”Ÿæˆæ›´æ–°æ‘˜è¦"""
        summary = []
        summary.append("# Centimani æ–°ç‰ˆæœ¬åˆ†ææ‘˜è¦")
        summary.append(f"*åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        summary.append("")
        
        # ç‰ˆæœ¬æ¯”è¼ƒæ‘˜è¦
        summary.append("## ğŸ”„ ç‰ˆæœ¬æ¯”è¼ƒ")
        summary.append("")
        
        if "ppt" in self.analysis_result["version_comparison"]:
            ppt_comp = self.analysis_result["version_comparison"]["ppt"]
            summary.append(f"### PPTç‰ˆæœ¬æ›´æ–°")
            summary.append(f"- **èˆŠç‰ˆæœ¬**: {ppt_comp['old_version']['version']} ({ppt_comp['old_version']['total_slides']} é )")
            summary.append(f"- **æ–°ç‰ˆæœ¬**: {ppt_comp['new_version']['version']} ({ppt_comp['new_version']['total_slides']} é )")
            summary.append(f"- **æ›´æ–°æ—¥æœŸ**: {ppt_comp['changes']['update_date']}")
            summary.append("")
        
        if "instrument_params" in self.analysis_result["version_comparison"]:
            inst_comp = self.analysis_result["version_comparison"]["instrument_params"]
            summary.append(f"### å„€å™¨åƒæ•¸æ›´æ–°")
            summary.append(f"- **èˆŠç‰ˆæœ¬**: {inst_comp['old_version']['version']}")
            summary.append(f"- **æ–°ç‰ˆæœ¬**: {inst_comp['new_version']['version']}")
            summary.append(f"- **ç‰ˆæœ¬å¢é‡**: {inst_comp['changes']['version_increment']}")
            summary.append(f"- **æ›´æ–°é–“éš”**: {inst_comp['changes']['time_gap']}")
            summary.append("")
        
        # æ–°åŠŸèƒ½æ‘˜è¦
        summary.append("## ğŸ†• æ–°åŠŸèƒ½èˆ‡æ”¹é€²")
        summary.append("")
        
        if "iplas_params" in self.analysis_result["new_versions"]:
            summary.append("### iPLASåƒæ•¸åˆ—è¡¨ v2.0")
            summary.append("- æ–°å¢å®Œæ•´çš„iPLASåƒæ•¸åƒè€ƒ")
            summary.append("- æä¾›v2.0ç‰ˆæœ¬çš„åƒæ•¸èªªæ˜")
            summary.append("- åŒ…å«æ›´å¤šå¯¦ç”¨åƒæ•¸å’Œè¨­å®šé¸é …")
            summary.append("")
        
        # æ›´æ–°å»ºè­°
        summary.append("## ğŸ’¡ æ›´æ–°å»ºè­°")
        summary.append("")
        
        for rec in self.analysis_result["recommendations"]:
            priority_icon = "ğŸ”´" if rec["priority"] == "high" else "ğŸŸ¡" if rec["priority"] == "medium" else "ğŸŸ¢"
            summary.append(f"{priority_icon} **{rec['type'].upper()}**: {rec['description']}")
            summary.append(f"   - å»ºè­°è¡Œå‹•: {rec['action']}")
            summary.append("")
        
        return "\n".join(summary)


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 70)
    print("Centimani æ–°ç‰ˆæœ¬åˆ†æå·¥å…·")
    print("=" * 70)
    
    # æª¢æŸ¥ä¾è³´å¥—ä»¶
    if not PPTX_AVAILABLE:
        print("âš ï¸  è­¦å‘Š: æœªå®‰è£python-pptxå¥—ä»¶")
        print("   è«‹åŸ·è¡Œ: pip install python-pptx")
        print()
    
    if not PANDAS_AVAILABLE:
        print("âš ï¸  è­¦å‘Š: æœªå®‰è£pandaså¥—ä»¶")
        print("   è«‹åŸ·è¡Œ: pip install pandas")
        print()
    
    # è¨­å®šæ–°ç‰ˆæœ¬æ–‡ä»¶è·¯å¾‘
    base_path = "../../Centimani DOC/CENTIMANIA/CENTIMANIA_2023_Platform_Training-20230718"
    
    if not os.path.exists(base_path):
        print(f"âŒ æœªæ‰¾åˆ°æ–°ç‰ˆæœ¬æ–‡ä»¶ç›®éŒ„: {base_path}")
        print("è«‹ç¢ºä¿æ–‡ä»¶ä½æ–¼æ­£ç¢ºä½ç½®")
        return
    
    try:
        # å‰µå»ºåˆ†æå™¨
        analyzer = NewVersionAnalyzer()
        
        # åˆ†ææ–°ç‰ˆæœ¬æ–‡ä»¶
        analysis_result = analyzer.analyze_new_versions(base_path)
        
        # ç”Ÿæˆæ›´æ–°æ‘˜è¦
        print("\nç”Ÿæˆæ›´æ–°æ‘˜è¦...")
        update_summary = analyzer.generate_update_summary()
        
        # ä¿å­˜åˆ†æå ±å‘Š
        print("\nä¿å­˜åˆ†æå ±å‘Š...")
        report_file = analyzer.save_analysis_report()
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        print("\n" + "=" * 70)
        print("åˆ†æçµæœæ‘˜è¦")
        print("=" * 70)
        
        if "new_versions" in analysis_result:
            for version_type, info in analysis_result["new_versions"].items():
                if "file_name" in info:
                    print(f"âœ… {version_type}: {info['file_name']}")
        
        print(f"ğŸ“„ åˆ†æå ±å‘Š: {report_file}")
        print("\nâœ… æ–°ç‰ˆæœ¬åˆ†æå®Œæˆï¼")
        
        # é¡¯ç¤ºæ›´æ–°æ‘˜è¦
        print("\n" + "=" * 70)
        print("æ›´æ–°æ‘˜è¦")
        print("=" * 70)
        print(update_summary)
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 